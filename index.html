<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>RL Diffusion Project</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <link rel="stylesheet" href="style.css">
</head>
<body>

<header>
  <nav>
    <div class="logo">RL-Diffusion</div>
    <div class="nav-links">
      <a href="icml2026__1_.pdf">Paper</a>
      <a href="#method">Method</a>
      <a href="#results">Results</a>
    </div>
  </nav>
</header>

<section class="hero center-text">
  <h1>Inference-Time Reward Alignment of Diffusion Models via Geometric Particle
Expansion</h1>
  <p>A new sequential monte carlo sampling method based
on geometric expansion</p>
</section>

<section class="hero">
  <h1 class="center-text">Summary</h1>
  <p>paper presents a derivative-free alignment approach for diffusion model inference to provide post-training optimization for non-differentiable rewards. We propose a geometric expansion in Sequential Monte Carlo–based sampling that does not require  reward  differentiation  at  any  stage of inference. Our approach generates additional particles via geometric noise based on the covariance of elite particles along dominant eigenvalue directions, followed by resampling at the same timestep to prevent weight degeneracy. </p>
  <p>our main contributions are as follows:
1. We propose Geometric Particle Expansion, a same-timestep, geometry-aware augmentation of SMC-guided diffusion sampling for derivative-free inference-time reward alignment.
2. We provide a theoretical proof that the geometric particle expansion is asymptotically negligible in the re-sampling distribution.
3. We empirically validate the performance of GPE in arrange of non-differentiable tasks, including image and molecular generation, and also evaluate its behavior under differentiable rewards.
</p>
</section>
  

<section id="illustration" class="section">
  <h2 class="center-text">SMC Illustrationt</h2>
  <p> Since direct sampling is intractable, we approximate this target using an empirical distribution
weighted by importance sampling within SMC. At each step, the SMC generates samples 
from a proposal distribution, with associated unnormalized importance weights to control weight degeneracy, SMC applies resampling with replacement, producing an equally weighted empirical measure supported on Dirac masses.
</p>
  <img src="particle expansion.png" alt="Illustration of particle expansion in the SMC">

  <p>
    Illustration of particle expansion in the SM
  </p>
</section>

<section id="method" class="section gray center-text">
  <h2>Method</h2>
  <p>
    We combine reinforcement learning with diffusion sampling to guide
    generation toward high-reward regions.
  </p>
</section>

<section id="results" class="section center-text">
  <h2>Results</h2>
  <div class="grid">
    <div class="card">
      <img src="particle expansion.png" alt="Illustration of particle expansion in the SMC">
      <p>Illustration of particle expansion in the SMC</p>
    </div>
  </div>
</section>

<section id="paper" class="section gray center-text">
  <h2>Paper</h2>
  <a class="button" href="#">Read the Paper</a>
</section>

<footer>
  <p>© 2026 Your Name</p>
</footer>

<script src="script.js"></script>
</body>
</html>
